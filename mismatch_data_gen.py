# Generate an AR process with mismatched AR coefficients - for training and evaluation of model

from utilities import matSave
import torch

# ARCoeffecientGeneration: Function that returns a matrix that works as an AR processes F matrix
#   Inputs:  (arCoeffMeans, arCoefficientNoiseVar)
#       arCoeffMeans (array) - mean values of the AR coefficients to be generated
#           arCoeffMeans[0] (float) - first AR coefficient
#           arCoeffMeans[1] (float) - second AR coefficient
#       arCoefficientNoiseVar (float) - variance of the AR coefficients to be generated
#   Outputs: (arCoeffMatrix)
#       arCoeffMatrix (tensor [2 x 2]) - the F matrix of an AR process (Bar-Shalom's notation)
#                                                                   
def ARCoeffecientGeneration(arCoeffMeans,arCoeffecientNoiseVar, seed=-1):
    if(seed > 0):
        torch.manual_seed(seed)

    arCoeffsMatrix = torch.eye(2)
    arCoeffsMatrix[1] = arCoeffsMatrix[0]
    goodCoeffs = False
    # Pre-Allocating the arCoeffNoise array
    arCoeffNoise = torch.empty(2,1, dtype=torch.float)
    eigValsEvaluated = torch.empty(2, dtype=torch.float)

    while(not goodCoeffs):
        # Generate new AR Coefficients until you get a pair who's eigenvalues are 
        # less than 1.
        # We do this because the system would explode to infinity if the eigenvalues 
        # were greater than 1.
        arCoeffNoise[0] = torch.randn(1) * arCoeffecientNoiseVar
        arCoeffNoise[1] = torch.randn(1) * arCoeffecientNoiseVar
        arCoeffsMatrix[0,0] = arCoeffMeans[0] + arCoeffNoise[0]
        arCoeffsMatrix[0,1] = arCoeffMeans[1] + arCoeffNoise[1]

        # Compute EigenValues of F
        eigValsEvaluated = torch.abs(torch.eig(arCoeffsMatrix, eigenvectors=False).eigenvalues) > 1
        # Determine if any of them have a greater magnitude than 1
        if (not eigValsEvaluated.any()):
            goodCoeffs=True
    return arCoeffsMatrix



# ARDatagenMismatch: Function that returns a set of data with a specified length, that
#                    comes from an AR process with AR coefficients that have some small
#                    amount of noise added to them
#   Inputs: (params, seed) {recent update removed the batch variable that needed to be passed,
#                           in order to streamline the data generation process. This change is
#                           quite large and will lead to the output of this function being
#                           in a new format from what it used to be, which may break old code
#                           working with this}
#       params (tuple) - a set of parameters to pass to the model
#           params[0] (int) - simLength: amount of batches of data to be generated by the
#                                        simulation
#           params[1] (int) - AR_n: The AR process order (The number of AR coefficients)
#           params[2] (float) - AR_coefficient_noise_var: variance in the AR coefficient from
#                                                         their mean
#           params[3] (int) - sequenceLength: length of the sequence of data to generate
#       seed (int) {default=a random number} - the seed of the random number generator
#                                              for this AR process
#       cuda (Bool) {default=False} - whether to use the GPU and cuda for data generation or not
#   Outputs: (data, params)
#       data (tuple) - tuple containing the data set that is generated by the AR Process
#
#            data[0] (tensor [2 x sequenceLength + 1  x simuLength]) - x: a tensor of all System States
#                                    of the AR Process separated into real and imaginary in the 1st
#                                    dimension, sequence elements in the 2nd dimension, and whole sequences
#                                    in the 3rd dimension
#                   x[0,i,j] (float) - real value of the System State at time i, of AR Process j
#                   x[1,i,j] (float) - imaginary value of the System State at time i of Process j
#
#            data[1] (tensor [2 x sequenceLength x simuLength]) - z: a tensor of all Observed States
#                                    of the AR Process, separated into real and imaginary in the 1st
#                                    dimension, sequence elements in the 2nd dimension, and into
#                                    groups of sequences in the 3rd dimension
#                   z[0,i,j] (float) - real value of the Observed State at time i, of AR Process j
#                   z[1,i,j] (float) - imaginary value of the Observed State at time i, of Process j
#
#            data[2] (tensor [4 x simuLength] - final_states: a tensor of final states that can be used
#                                    to compare results from the output of the predictor and estimator
#                                    with the actual values of a sequence. In the 1st dimension it is grouped
#                                    into real and imaginary portions of the last state (prediction value) and
#                                    the second from last state (estimated value), in the 2nd dimension its
#                                    separated into groups of sequences
#                   final_states[0,i] (float) - real value of the estimated (second to last) System State
#                                               of AR Process i
#                   final_states[1,i] (float) - real value of the predicted (last) System State of AR
#                                               Process i
#                   final_states[2,i] (float) - imaginary value of the estimated (second to last) System
#                                               State of AR Process i
#                   final_states[3,i] (float) - imaginary value of the predicted (last) System State of
#                                               AR Process i
#
#       info (dict) - a tuple of information about the data generated by this function
#           info['filename'] (str) - the name of the file that the data was saved to
#           info['seed'] (int) - the seed that was used for data generation (will be the same value passed to it if a
#                                 a seed was passed to the function
# Vocabulary definitions:
#   Sequence: A set of data generated from the same AR process. Has correlation between elements
#   Series: A set of data generated to be processed once by the model. Each element is a sequence of data
#           from an AR Process

# Additional Notes about this function:
#   - This function saves all values that it returns to a .mat data file, including the parameters
#     it used to generate the data. This file name will be printed when it is saved
def ARDatagenMismatch(params, seed=int(torch.abs(torch.floor(100*torch.randn(1)))), cuda=False):
    # Set the seed value for repeatable results
    simLength = params[0]
    AR_n = params[1]
    AR_coeffecient_noise_var = params[2]
    sequenceLength = params[3]
    torch.manual_seed(seed)


    # Gain matrix on the previous values
    # TODO: Make the AR coefficient means be a parameter you can pass to the function
    arCoeffMeans = torch.tensor([0.5, 0.4])

    # Noise covariance matrix / noise mean
    Q = torch.tensor([[0.1, 0], [0, 0]])
    QChol = torch.tensor([[torch.sqrt(Q[0,0]), 0],[0, 0]])

    # Observation covariance matrix/ noise mean
    R = torch.tensor([0.1])

    # Pre-allocating the matrix that will store the true values of the predicted and current state
    x = torch.zeros((2, sequenceLength + 1, simLength), dtype=torch.float)
    # Pre-allocating the matrix that will store the measured data to be fed into the model
    z = torch.zeros((2, sequenceLength, simLength), dtype=torch.float)

    # Pre-allocating for the system noise vector
    # Matrix format: 1st element is the real part of the noise, 2nd element is the imaginary part of the noise,
    #                1st dimension is current state noise, 2nd dimension is the last state noise (this will always
    #                be 0)
    v = torch.empty(2,2, dtype=torch.float)

    # Pre-allocating for the observation noise vector
    # Matrix format: 1st element is the real part of the noise, 2nd element is the imaginary part of the noise
    w = torch.empty(2, dtype=torch.float)

    # Pre-allocating for the current true state and observed state vectors
    # Matrix format (x_complex): 1st dimension is the current state, 2nd dimension is the previous state,
    #                            first element of each dimension is the real part of the state, second element
    #                            is the imaginary portion of the current state
    x_complex = torch.empty(2,2,dtype=torch.float)

    # Matrix format (z_complex): 1st element is the real value of the current observed state, 2nd element is
    #                            the imaginary portion of the observed state
    z_complex = torch.empty(2, dtype=torch.float)

    # Pre-allocating a matrix to save just the last state (to be predicted) and the second last state (to
    # be estimated)
    # Matrix format is
    final_states = torch.zeros((4, simLength), dtype=torch.float)

    if(cuda):
        v.cuda()
        w.cuda()

        x_complex.cuda()
        z_complex.cuda()

        z.cuda()
        x.cuda()

        R.cuda()
        Q.cuda()
        QChol.cuda()

        arCoeffMeans.cuda()

        final_states.cuda()


    ### Loop for generating all the batches of data (a series) ###
    for i in range(0,simLength):
        # Compute new AR Coefficients for each sequence
        F = ARCoeffecientGeneration(arCoeffMeans, AR_coeffecient_noise_var)
        ## Loop for generating a sequence of data
        for n in range(0,sequenceLength + 1):
            # Generate system noise vector
            rSysNoise = torch.div(torch.matmul(QChol,
                                    torch.randn(AR_n, 1)), torch.sqrt(torch.tensor(2, dtype=torch.float)))
            iSysNoise = torch.div(torch.matmul(QChol,
                                    torch.randn(AR_n, 1)), torch.sqrt(torch.tensor(2, dtype=torch.float)))
            # Forced to squeeze the noise values because they needed to be 2x1 tensors to multiply, but v[0]
            # is 2x in dimension (same for v[1])
            v[:,0] = torch.squeeze(rSysNoise)
            v[:,1] = torch.squeeze(iSysNoise)

            # Generate observation noise vector
            rObsNoise = torch.div(torch.matmul(torch.sqrt(R),
                                    torch.randn(1)),torch.sqrt(torch.tensor(2, dtype=torch.float)))
            iObsNoise = torch.div(torch.matmul(torch.sqrt(R),
                                    torch.randn(1)),torch.sqrt(torch.tensor(2, dtype=torch.float)))
            w[0] = torch.squeeze(rObsNoise)
            w[1] = torch.squeeze(iObsNoise)
            # On first iteration through make the noise equal to zero so there the initial state starts at 0
            if(n==0):
                x_complex = torch.zeros(2,2, dtype=torch.float)
                z_complex = torch.zeros(2, dtype=torch.float)
            else:
                x_complex = torch.matmul(F,x_complex)
                x_complex = x_complex + v
                z_complex = x_complex[0] + w
            if (n < sequenceLength):
                # Storing the measured data in its appropriate batch element, its appropriate
                # complex and real components, its appropriate sequence element, and the right
                # series element
                z[0, n, i] = z_complex[0]
                z[1, n, i] = z_complex[1]

            # Storing the true states
            x[0, n, i] = x_complex[0,0]
            x[1, n, i] = x_complex[0,1]

            # If we are on the sequenceLength + 1 iteration we need to grab the current
            # true state (will be the next predicted true state from the measurements),
            # and the previous actual state (will be the current true state from the
            # measurements) for the final states value
            if(n==sequenceLength):
                final_states[0,i] = x_complex[1,0]
                final_states[1,i] = x_complex[0,0]
                final_states[2,i] = x_complex[1,1]
                final_states[3,i] = x_complex[0,1]


    ##### Storing the data #####
    storageFilePath = './data'
    dataFile = 'data'
    logContent = {}
    logContent[u'observedStates'] = z.numpy()
    logContent[u'systemStates'] = x.numpy()
    logContent[u'finalStateValues'] = final_states.numpy()
    logContent[u'parameters'] = params
    logContent[u'seed'] = seed
    logContent[u'cuda'] = cuda
    filename = matSave(storageFilePath,dataFile,logContent)

    data=(x.numpy(), z.numpy(), final_states.numpy())

    info = {}
    info[u'filename'] = filename
    info[u'seed'] = seed

    # Return data
    return(data, info)
